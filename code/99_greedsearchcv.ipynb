{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('data_2018_11_27.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label=pd.read_csv('label.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label.columns=['hash','ismal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge=pd.merge(data,label,on='hash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=merge.copy()\n",
    "del X['hash']\n",
    "del X['ismal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=merge['ismal']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xgb boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - 이전 베스트 파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    " Best estimator:\n",
    "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=1, colsample_bytreeb=0.8, gamma=0,\n",
    "       learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
    "       min_child_weight=1, missing=None, n_estimators=900, n_jobs=1,\n",
    "       nthread=1, objective='binary:logistic', random_state=0, reg_alpha=0,\n",
    "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
    "       subsample=0.8)\n",
    "\n",
    " Best hyperparameters:\n",
    "{'colsample_bytreeb': 0.8, 'gamma': 0, 'max_depth': 10, 'min_child_weight': 1, 'n_estimators': 900, 'subsample': 0.8}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed: 15.2min\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed: 21.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Best estimator:\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, colsample_bytreeb=0.8, gamma=0,\n",
      "       learning_rate=0.1, max_delta_step=0, max_depth=10,\n",
      "       min_child_weight=1, missing=None, n_estimators=900, n_jobs=1,\n",
      "       nthread=1, objective='binary:logistic', random_state=0, reg_alpha=0,\n",
      "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
      "       subsample=0.8)\n",
      "\n",
      " Best hyperparameters:\n",
      "{'colsample_bytreeb': 0.8, 'gamma': 0, 'max_depth': 10, 'min_child_weight': 1, 'n_estimators': 900, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#XGB부스트 \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import  GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "params = {\n",
    "        'n_estimators' : [600,700,800,900,1000], #중요\n",
    "        'min_child_weight': [1] #1,5 # 1이 대부분 좋다..\n",
    "        'gamma': [0], #  1, 1.5, 2, 5 - 큰 차이 없음\n",
    "        'subsample': [0.8], #06,0.8,1.0 -> 큰 차이 없음\n",
    "        'colsample_bytreeb' : [ 0.8], #06,0.8,1.0 -> 큰 차이 없음\n",
    "        'max_depth': [5,7,10] #중요\n",
    "        }\n",
    "\n",
    "# 여기서 돌리고 최적 나오면 그 parameter 근처 값들로 다시 그리드 진행하면 될듯 \n",
    "# https://www.programcreek.com/python/example/99824/xgboost.XGBClassifier 참고하기 좋은 자료\n",
    "\n",
    "xgb = XGBClassifier(learning_rate=0.1, n_estimators=600, objective='binary:logistic',\n",
    "                    silent=True, nthread=1)\n",
    "\n",
    "\n",
    "grid_search1 = GridSearchCV(xgb, param_grid=params, scoring='accuracy', n_jobs=-1, cv=2, verbose=3 )\n",
    "grid_search1.fit(X, Y)\n",
    "\n",
    "print('\\n Best estimator:')\n",
    "\n",
    "print(grid_search1.best_estimator_)\n",
    "print('\\n Best hyperparameters:')\n",
    "print(grid_search1.best_params_)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9523"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search1.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best parameter\n",
    "#{'max_depth': 90, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   41.8s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 90, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# RANDOMFOREST\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 500, num = 5)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['sqrt']\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [60,70,80,90,100] #40,50\n",
    "#int(x) for x in np.linspace(10, 30, num = 3)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2] #10 \n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1] #4\n",
    "\n",
    "\n",
    "# Create the random grid\n",
    "param_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "# Create a based model\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search2 = GridSearchCV(estimator = clf, param_grid = param_grid,scoring='accuracy',\n",
    "                          cv = 2, n_jobs = -1, verbose = 2)\n",
    "grid_search2.fit(X, Y)\n",
    "\n",
    "print(grid_search2.best_params_)\n",
    "best_grid = grid_search2.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9478"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search2.best_score_ #0.947"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 엑스트라 트리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#{'max_depth': 40, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 21 candidates, totalling 42 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   33.9s\n",
      "[Parallel(n_jobs=-1)]: Done  42 out of  42 | elapsed:   41.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 40, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 300,num=3)]\n",
    "\n",
    "\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [40,50,60,70,80,90,100]\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2]#2,5,10\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1] #2,5,10\n",
    "\n",
    "\n",
    "# Create the random grid\n",
    "param_grid = {'n_estimators': n_estimators,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "# Create a based model\n",
    "clf = ExtraTreesClassifier()\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search3 = GridSearchCV(estimator = clf, param_grid = param_grid, scoring='accuracy'\n",
    "                          cv = 2, n_jobs = -1, verbose = 2)\n",
    "grid_search3.fit(X, Y)\n",
    "print(grid_search3.best_params_)\n",
    "best_grid = grid_search3.best_estimator_\n",
    "best_score=grid_search3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=40, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# light gbm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best parameter\n",
    "#{'boosting_type': 'gbdt', 'colsample_bytree': 0.65, 'learning_rate': 0.005, 'n_estimators': 1400, 'num_leaves': 90, 'objective': 'binary', 'random_state': 501, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  1.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'boosting_type': 'gbdt', 'colsample_bytree': 0.65, 'learning_rate': 0.005, 'n_estimators': 1400, 'num_leaves': 90, 'objective': 'binary', 'random_state': 501, 'reg_alpha': 1, 'reg_lambda': 1, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Create the random grid\n",
    "param_grid = { 'learning_rate': [0.005], #0.1,0.001\n",
    "    'n_estimators': [1400], # 높일수록 올라가는데 어느정도 되면 큰 차이 없음\n",
    "    'num_leaves' :[30,50,90] \n",
    "best_score=grid_search3.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9514"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cat boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2156e32a3e89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m grid_search3 = GridSearchCV(estimator = clf, param_grid = params, scoring='accuracy',\n\u001b[0;32m     18\u001b[0m                           cv = 2, n_jobs = -1, verbose = 2)\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mgrid_search3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrid_search3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mbest_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_search3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import catboost as cb\n",
    "cat_features_index = [0,1,2,3,4,5,6]\n",
    "\n",
    "\n",
    "params = {'depth': [7,10], \n",
    "          'learning_rate' : [0.15,], #0.03, 0.1\n",
    "         'l2_leaf_reg': [1,4], #4,9\n",
    "         'iterations': [600]}\n",
    "\n",
    "\n",
    "\n",
    "# Create a based model\n",
    "clf = cb.CatBoostClassifier()\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search3 = GridSearchCV(estimator = clf, param_grid = params, scoring='accuracy',\n",
    "                          cv = 2, n_jobs = -1, verbose = 2)\n",
    "grid_search3.fit(X, Y)\n",
    "print(grid_search3.best_params_)\n",
    "best_grid = grid_search3.best_estimator_\n",
    "best_score=grid_search3.best_score_\n",
    "\n",
    "# cb_model = GridSearchCV(cb, params, scoring=\"roc_auc\", cv = 3)\n",
    "# cb_model.fit(train, y_train)\n",
    "\n",
    "# With Categorical features\n",
    "# clf = cb.CatBoostClassifier(eval_metric=\"AUC\", depth=10, iterations= 500, l2_leaf_reg= 9, learning_rate= 0.15)\n",
    "# clf.fit(train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
